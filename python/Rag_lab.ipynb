{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cb8f7ae-16c5-4714-9fef-1a577ac36a85"
      },
      "source": [
        "# RAG with Qwen, FAISS, PDFs, and Spreadsheets\n",
        "\n",
        "This notebook is designed for teaching  how **Retrieval-Augmented Generation (RAG)** works in practice.\n",
        "\n",
        "They will see:\n",
        "\n",
        "1. How we turn text into embeddings (vectors that represent meaning).\n",
        "2. How we store those vectors in a **vector database** (FAISS).\n",
        "3. How we **retrieve** relevant information for a question.\n",
        "4. How we give that information to a language model (Qwen) to get grounded answers.\n",
        "5. How to upload **PDFs** and **spreadsheets** and make them part of the knowledge base.\n"
      ],
      "id": "5cb8f7ae-16c5-4714-9fef-1a577ac36a85"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73e13b5b-71c8-46b7-9cf7-a603a50f984e"
      },
      "source": [
        "## What is RAG?\n",
        "\n",
        "**RAG = Retrieval-Augmented Generation.**\n",
        "\n",
        "The idea:\n",
        "\n",
        "1. A user asks a question.\n",
        "2. We **retrieve** relevant pieces of text from our documents.\n",
        "3. We feed those pieces + the question into a language model.\n",
        "4. The model **generates** an answer that uses the retrieved context.\n",
        "\n",
        "Without RAG, the model is guessing from what it learned during pretraining.\n",
        "With RAG, the model is allowed to \"look things up\" in our own data first.\n",
        "\n",
        "Diagram:\n",
        "\n",
        "```text\n",
        "User question\n",
        "      |\n",
        "      v\n",
        "+-------------------+\n",
        "|  Embedding model  |  -> question vector\n",
        "+-------------------+\n",
        "      |\n",
        "      v\n",
        "+------------------------+\n",
        "|  Vector database       |  -> find similar document vectors\n",
        "|      (FAISS)           |\n",
        "+------------------------+\n",
        "      |\n",
        "      v\n",
        "+----------------------+\n",
        "|  Retrieved context   |\n",
        "+----------------------+\n",
        "      |\n",
        "      v\n",
        "+------------------------------+\n",
        "|  Language model (Qwen)       |\n",
        "+------------------------------+\n",
        "      |\n",
        "      v\n",
        "Answer, using your documents\n",
        "```\n"
      ],
      "id": "73e13b5b-71c8-46b7-9cf7-a603a50f984e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2344ea3a-8c08-492c-bcde-5429fd72887f"
      },
      "source": [
        "## Step 1 — Install Dependencies\n",
        "\n",
        "We install:\n",
        "\n",
        "- `transformers` + `accelerate` to load and run Qwen.\n",
        "- `sentence-transformers` for the embedding model.\n",
        "- `faiss-cpu` for vector search.\n",
        "- `pypdf` to extract text from PDFs.\n",
        "- `pandas` + `openpyxl` to read spreadsheets (CSV/XLSX).\n"
      ],
      "id": "2344ea3a-8c08-492c-bcde-5429fd72887f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25532848-6e02-4ddc-b57b-5e38b0f3d8c8"
      },
      "source": [
        "!pip install -q transformers accelerate sentence-transformers faiss-cpu pypdf pandas openpyxl"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "25532848-6e02-4ddc-b57b-5e38b0f3d8c8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a1d1518-cb79-46ed-85c2-d97f8e57ebf6"
      },
      "source": [
        "## Step 2 — Load the Embedding Model\n",
        "\n",
        "We use `BAAI/bge-small-en-v1.5` as our embedding model.\n",
        "\n",
        "What this model does:\n",
        "\n",
        "- Input: text (a sentence, paragraph, or document).\n",
        "- Output: a **vector** (a list of numbers) that represents the meaning of that text.\n",
        "\n",
        "Similar meanings → similar vectors.\n",
        "\n",
        "Diagram:\n",
        "\n",
        "```text\n",
        "Text: \"Python is a popular programming language.\"\n",
        "\n",
        "         Embedding model\n",
        "   +-------------------------+\n",
        "   | BGE-small-en-v1.5       |\n",
        "   +-------------------------+\n",
        "                 |\n",
        "                 v\n",
        "Vector: [ -0.12, 0.88, 0.31, -0.44, ..., 0.05 ]\n",
        "\n",
        "Another sentence like:\n",
        "\"Python is widely used in AI and data science.\"\n",
        "\n",
        "produces a vector that is close in this high-dimensional space.\n",
        "```\n"
      ],
      "id": "0a1d1518-cb79-46ed-85c2-d97f8e57ebf6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "692fbf37-3709-4f74-ae48-26c07302926b"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "embedder = SentenceTransformer(\"BAAI/bge-small-en-v1.5\")\n",
        "print(\"Embedding model loaded!\")\n",
        "\n",
        "# Detect the embedding dimension dynamically so FAISS always matches.\n",
        "EMBED_DIM = embedder.get_sentence_embedding_dimension()\n",
        "print(\"Embedding dimension:\", EMBED_DIM)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "692fbf37-3709-4f74-ae48-26c07302926b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a63d4c76-cd4a-4a0b-9503-821ee49927e8"
      },
      "source": [
        "## Step 3 — Load the Qwen Language Model\n",
        "\n",
        "We load a small Qwen chat model.\n",
        "\n",
        "Key points for students:\n",
        "\n",
        "- Qwen is the **generator**: it turns text prompts into answers.\n",
        "- It does **not** store your PDFs or spreadsheets internally.\n",
        "- It works best when we give it the right context (via RAG).\n",
        "\n",
        "We use the `dtype` parameter (recommended) for the tensor type.\n"
      ],
      "id": "a63d4c76-cd4a-4a0b-9503-821ee49927e8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8d294ebb-4510-40b4-8b8a-5343e27fbe1e"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "model_name = \"Qwen/Qwen1.5-1.8B-Chat\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    dtype=torch.float32,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "print(\"Qwen model loaded!\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "8d294ebb-4510-40b4-8b8a-5343e27fbe1e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c6e4b3e-44fd-479c-a3df-7c8331d5fa61"
      },
      "source": [
        "## Step 4 — Create the FAISS Vector Index\n",
        "\n",
        "Now we set up a **vector database** using FAISS.\n",
        "\n",
        "What FAISS does:\n",
        "\n",
        "- Stores many embedding vectors.\n",
        "- Given a new vector (from a question), quickly finds the most similar stored vectors.\n",
        "- Those matches correspond to our most relevant documents.\n",
        "\n",
        "Diagram:\n",
        "\n",
        "```text\n",
        "         FAISS index (vector database)\n",
        "       +------------------------------+\n",
        "       |  vec_0  -> doc_0 (text)      |\n",
        "       |  vec_1  -> doc_1 (text)      |\n",
        "       |  vec_2  -> doc_2 (text)      |\n",
        "       |   ...                        |\n",
        "       +------------------------------+\n",
        "```\n"
      ],
      "id": "9c6e4b3e-44fd-479c-a3df-7c8331d5fa61"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15dbd5e7-756c-4bd2-8fb7-c0cdec196b9d"
      },
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# Create a simple L2 index with the correct dimension\n",
        "index = faiss.IndexFlatL2(EMBED_DIM)\n",
        "\n",
        "# Store raw texts and simple metadata\n",
        "documents = []   # list of text\n",
        "sources = []     # where each text came from (manual, pdf filename, spreadsheet name, etc.)\n",
        "\n",
        "print(\"FAISS index created with dimension:\", EMBED_DIM)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "15dbd5e7-756c-4bd2-8fb7-c0cdec196b9d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fb9dea3-fa25-426f-89a8-c6b90a2c9ed4"
      },
      "source": [
        "## Step 5 — Helper Functions (Add Documents, PDFs, Spreadsheets)\n",
        "\n",
        "To avoid missing definitions, **all core helper functions are defined in one cell**:\n",
        "\n",
        "- `add_document(text, source)`\n",
        "- `upload_pdf()`\n",
        "- `upload_spreadsheet()`\n",
        "\n",
        "This way, students only need to run this one cell to get all core behaviors.\n"
      ],
      "id": "5fb9dea3-fa25-426f-89a8-c6b90a2c9ed4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4302515-aac3-4a6d-9524-ac11ba67c5d2"
      },
      "source": [
        "from typing import List\n",
        "from pypdf import PdfReader\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "def add_document(text: str, source: str = \"manual\"):\n",
        "    \"\"\"Embed the text, add it to FAISS, and record its source.\n",
        "\n",
        "    text   : the raw text to store\n",
        "    source : a short label like 'manual', 'myfile.pdf', or 'grades.xlsx'\n",
        "    \"\"\"\n",
        "    if not text.strip():\n",
        "        print(\"Skipped empty text.\")\n",
        "        return\n",
        "\n",
        "    embedding = embedder.encode([text])[0].astype(\"float32\")\n",
        "    index.add(np.array([embedding]))\n",
        "    documents.append(text)\n",
        "    sources.append(source)\n",
        "    print(f\"Added document #{len(documents)} from source: {source} (length={len(text)} chars)\")\n",
        "\n",
        "\n",
        "def upload_pdf():\n",
        "    \"\"\"Upload one or more PDFs, extract all text, and add each as a document.\n",
        "\n",
        "    Each uploaded PDF becomes one document in FAISS.\n",
        "    For more advanced use, you could split large PDFs into chunks.\n",
        "    \"\"\"\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "        reader = PdfReader(filename)\n",
        "        full_text = \"\"\n",
        "        for page in reader.pages:\n",
        "            page_text = page.extract_text() or \"\"\n",
        "            full_text += page_text + \"\\n\"\n",
        "        print(f\"[PDF] Extracted {len(full_text)} characters from {filename}\")\n",
        "        add_document(full_text, source=filename)\n",
        "\n",
        "\n",
        "def upload_spreadsheet():\n",
        "    \"\"\"Upload one or more spreadsheets (CSV or Excel) and add them as text documents.\n",
        "\n",
        "    Strategy:\n",
        "    - If CSV: read with pandas.read_csv.\n",
        "    - If Excel: read with pandas.read_excel (requires openpyxl).\n",
        "    - Convert DataFrame to CSV-style text string.\n",
        "    - Store that text in FAISS so it can be retrieved semantically.\n",
        "    \"\"\"\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "        if filename.lower().endswith(\".csv\"):\n",
        "            df = pd.read_csv(filename)\n",
        "        else:\n",
        "            df = pd.read_excel(filename)\n",
        "        text = df.to_csv(index=False)\n",
        "        print(f\"[Spreadsheet] {filename}: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
        "        add_document(text, source=filename)\n",
        "\n",
        "\n",
        "print(\"Helper functions defined: add_document(), upload_pdf(), upload_spreadsheet()\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "e4302515-aac3-4a6d-9524-ac11ba67c5d2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55f53bbd-0206-4a11-bb7c-4f4bffff8eba"
      },
      "source": [
        "## Step 6 — Add Some Sample Documents\n",
        "\n",
        "We add a few short texts so students can immediately test the system.\n",
        "\n",
        "Later, they can:\n",
        "\n",
        "- Upload their own PDFs.\n",
        "- Upload their own spreadsheets.\n",
        "- See how retrieval and answers change.\n"
      ],
      "id": "55f53bbd-0206-4a11-bb7c-4f4bffff8eba"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d807dddc-34c9-4a0d-b958-4841525a563c"
      },
      "source": [
        "add_document(\"Python is a high-level programming language widely used in data science and AI.\", source=\"sample: python\")\n",
        "add_document(\"Retrieval-Augmented Generation (RAG) retrieves relevant documents before the model generates an answer.\", source=\"sample: rag\")\n",
        "add_document(\"Google Cloud provides scalable infrastructure for machine learning, storage, and databases.\", source=\"sample: gcp\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "d807dddc-34c9-4a0d-b958-4841525a563c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ff138ba-04bd-4b12-9688-4da837f33f11"
      },
      "source": [
        "## Step 7 — RAG Query Function\n",
        "\n",
        "This function runs the full RAG pipeline:\n",
        "\n",
        "1. Embed the question.\n",
        "2. Use FAISS to find the most similar documents.\n",
        "3. Build a **context** string from those documents.\n",
        "4. Construct a prompt that includes the context and the question.\n",
        "5. Ask Qwen to generate an answer.\n",
        "\n",
        "Diagram:\n",
        "\n",
        "```text\n",
        "Question\n",
        "  |\n",
        "  v\n",
        "Embedding model --> question vector\n",
        "  |\n",
        "  v\n",
        "FAISS index --> indices of closest documents\n",
        "  |\n",
        "  v\n",
        "Context = joined documents\n",
        "  |\n",
        "  v\n",
        "Qwen model --> final answer\n",
        "```\n"
      ],
      "id": "9ff138ba-04bd-4b12-9688-4da837f33f11"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "627c73db-bbe4-4b4d-9671-81477de5a308"
      },
      "source": [
        "def rag_query(query: str, top_k: int = 3, show_sources: bool = True) -> str:\n",
        "    # 1. Embed the query\n",
        "    q_embedding = embedder.encode([query])[0].astype(\"float32\")\n",
        "\n",
        "    # 2. Search FAISS\n",
        "    distances, indices = index.search(np.array([q_embedding]), top_k)\n",
        "\n",
        "    # 3. Build context from the closest documents\n",
        "    retrieved_docs = []\n",
        "    retrieved_meta = []\n",
        "    for idx in indices[0]:\n",
        "        if 0 <= idx < len(documents):\n",
        "            retrieved_docs.append(documents[idx])\n",
        "            retrieved_meta.append(sources[idx])\n",
        "\n",
        "    context = \"\\n\\n---\\n\\n\".join(retrieved_docs)\n",
        "\n",
        "    if show_sources:\n",
        "        print(\"Retrieved from sources:\")\n",
        "        for m in retrieved_meta:\n",
        "            print(\" -\", m)\n",
        "        print()\n",
        "\n",
        "    # 4. Build prompt\n",
        "    prompt = f\"\"\"You are a helpful assistant.\n",
        "\n",
        "You will be given some context from documents, followed by a question.\n",
        "Use only the information in the context to answer as accurately as possible.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {query}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "    # 5. Generate answer with Qwen\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "    output = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=300,\n",
        "        temperature=0.2\n",
        "    )\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "627c73db-bbe4-4b4d-9671-81477de5a308"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe8f7d47-f4ba-4fc7-a9a8-351bec4e588f"
      },
      "source": [
        "## Step 8 — Test the System\n",
        "\n",
        "Now we can ask a question and see:\n",
        "\n",
        "- Which sources FAISS retrieved.\n",
        "- How Qwen answers using that context.\n"
      ],
      "id": "fe8f7d47-f4ba-4fc7-a9a8-351bec4e588f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09c16e34-d82b-4c0b-b09b-a08917b28660"
      },
      "source": [
        "print(rag_query(\"What is Q-Mos?\"))"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "09c16e34-d82b-4c0b-b09b-a08917b28660"
    },
    {
      "cell_type": "code",
      "source": [
        "upload_pdf()\n"
      ],
      "metadata": {
        "id": "ZSUknLjEq8ls"
      },
      "id": "ZSUknLjEq8ls",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fccdaa33-8e4f-4638-9b87-b8c72104176f"
      },
      "source": [
        "## Step 9 —  Exercises\n",
        "\n",
        "Things to try:\n",
        "\n",
        "1. **Upload a PDF** using `upload_pdf()` and then ask questions about it.\n",
        "2. **Upload a spreadsheet** using `upload_spreadsheet()` and ask questions like:\n",
        "   - \"Which region has the highest sales?\"\n",
        "   - \"Which students have the lowest grades?\"\n",
        "3. Modify `top_k` in `rag_query` and observe how the answer changes.\n",
        "4. Print out the raw `context` inside `rag_query` to see exactly what the model saw.\n",
        "5. Split large documents into smaller logical chunks (per page, per section) and store each chunk separately for more precise retrieval.\n",
        "\n",
        "This helps you understand:\n",
        "\n",
        "- The difference between **raw data** and **retrieved context**.\n",
        "- How better retrieval leads to better answers.\n",
        "- Why vector databases and embeddings are powerful in modern data science and AI systems.\n"
      ],
      "id": "fccdaa33-8e4f-4638-9b87-b8c72104176f"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}